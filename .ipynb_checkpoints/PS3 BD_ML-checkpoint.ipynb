{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2016,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr as pyr\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "from contexto.limpieza import *\n",
    "from contexto.lectura import leer_texto\n",
    "from contexto.exploracion import grafica_barchart_frecuencias\n",
    "from contexto.exploracion import obtener_ngramas, par_nubes\n",
    "from contexto.lematizacion import lematizar_texto\n",
    "from contexto.correccion import corregir_texto\n",
    "from contexto.lematizacion import LematizadorSpacy\n",
    "from contexto.exploracion import obtener_ngramas\n",
    "from contexto.exploracion import frecuencia_ngramas\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import chi2\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import make_scorer\n",
    "from numpy.random import normal\n",
    "from numpy.random import seed\n",
    "from sklearn.linear_model import Lasso\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys([None])\n",
      "odict_keys([None])\n"
     ]
    }
   ],
   "source": [
    "#Set directory:\n",
    "os.chdir(\"C:/Users/juand/Desktop/Big Data/Taller 3/dataPS3\")\n",
    "tr=pyr.read_r(\"train.Rds\") \n",
    "tt=pyr.read_r(\"test.Rds\")\n",
    "print(tr.keys())\n",
    "print(tt.keys())\n",
    "df_tr=tr[None] #Train Data frame (Bogotá D.C. y Medellín). \n",
    "df_tt=tt[None] #Test Data frame (Cali). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr.drop(\"rooms\", axis=1, inplace=True) #Correct bedrooms data.\n",
    "df_tt.drop(\"rooms\", axis=1, inplace=True) #Correct bedrooms data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2020,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw=stopwords.words('spanish')\n",
    "stopw.append(\"br\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2021,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Funcion para limpiar todos los textos\n",
    "def limp_texto(text):\n",
    "    #textocorr=lematizar_texto(str(text), lenguaje='es', libreria='spacy', limpiar=False)\n",
    "    textolimpio=limpieza_texto(str(text), lista_palabras=stopw, quitar_numeros=False, quitar_acentos=True)\n",
    "    return textolimpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sc.stats.mstats.winsorize(df_tr[\"price\"], limits=[0,0.05], inplace=True)\n",
    "y_millones=y/1000000\n",
    "plt.hist(y_millones, bins=50, color = (0.17, 0.44, 0.69, 0.9))\n",
    "plt.xlim(200,2210)\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.xlabel(\"COP (millones)\")\n",
    "plt.savefig(\"histy_precios.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descripciontr = df_tr[\"description\"].tolist()\n",
    "#descripcionlimptr=[limp_texto(i) for i in descripciontr]\n",
    "#listacomptr=\" \".join(descripcionlimptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descripciontt = df_tt[\"description\"].tolist()\n",
    "#descripcionlimptt=[limp_texto(i) for i in descripciontt]\n",
    "#listacomptt=\" \".join(descripcionlimptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frecuencia bigramas total\n",
    "#bigramastr = frecuencia_ngramas(listacomptr, 1)\n",
    "#bigramastrsort=dict(sorted(bigramastr.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frecuencia bigramas por precio\n",
    "#Percentiles de precio\n",
    "#df_trlow=df_tr[df_tr[\"price\"]<=df_tr.price.quantile(0.1)]\n",
    "#descripciontrlow = df_trlow[\"description\"].tolist()\n",
    "#descripcionlimptrlow=[limp_texto(i) for i in descripciontrlow]\n",
    "#listacomptrlow=\" \".join(descripcionlimptrlow)\n",
    "#bigramastrlow = frecuencia_ngramas(listacomptrlow, 1)\n",
    "#bigramastrsortlow=dict(sorted(bigramastrlow.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frecuencia bigramas por precio\n",
    "#Percentiles de precio\n",
    "#df_trlow=df_tr[df_tr[\"price\"]>=df_tr.price.quantile(0.9)]\n",
    "#descripciontrlow = df_trlow[\"description\"].tolist()\n",
    "#descripcionlimptrlow=[limp_texto(i) for i in descripciontrlow]\n",
    "#listacomptrlow=\" \".join(descripcionlimptrlow)\n",
    "#bigramastrlow = frecuencia_ngramas(listacomptrlow, 1)\n",
    "#bigramastrsorthigh=dict(sorted(bigramastrlow.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Dummies de cada caracteristicas\n",
    "#Cleaning description\n",
    "#Training ######### \n",
    "descripciontr = df_tr[\"description\"].tolist()\n",
    "descripcionlimptr=[limp_texto(i) for i in descripciontr]\n",
    "df_tr[\"description\"]=pd.DataFrame(descripcionlimptr)\n",
    "#title\n",
    "titulotr = df_tr[\"title\"].tolist()\n",
    "titulolimptr=[limp_texto(i) for i in titulotr]\n",
    "df_tr[\"title\"]=pd.DataFrame(titulolimptr)\n",
    "\n",
    "#Test#############\n",
    "descripciontr = df_tt[\"description\"].tolist()\n",
    "descripcionlimptr=[limp_texto(i) for i in descripciontr]\n",
    "df_tt[\"description\"]=pd.DataFrame(descripcionlimptr)\n",
    "#title\n",
    "titulotr = df_tt[\"title\"].tolist()\n",
    "titulolimptr=[limp_texto(i) for i in titulotr]\n",
    "df_tt[\"title\"]=pd.DataFrame(titulolimptr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummies tipo propiedad\n",
    "tipo_d=pd.get_dummies(df_tr[\"property_type\"], prefix=\"tipo\")\n",
    "df_tr=pd.merge(df_tr, tipo_d, left_index=True, right_index=True)\n",
    "tipo_dt=pd.get_dummies(df_tt[\"property_type\"], prefix=\"tipo\")\n",
    "df_tt=pd.merge(df_tt, tipo_dt, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2030,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics:\n",
    "#tipo_d=pd.get_dummies(df_tr[\"property_type\"], prefix=\"tipo\")\n",
    "#df_tr=pd.merge(df_tr, tipo_d, left_index=True, right_index=True)\n",
    "#tipo_dt=pd.get_dummies(df_tt[\"property_type\"], prefix=\"tipo\")\n",
    "#df_tt=pd.merge(df_tt, tipo_dt, left_index=True, right_index=True)\n",
    "\n",
    "#Train:\n",
    "#df_tr[\"bathrooms\"]=df_tr[\"bathrooms\"].astype(\"float\")\n",
    "#ds_tr=(df_tr[[\"tipo_Apartamento\", \"surface_total\", \"bedrooms\", \"bathrooms\"]].describe(include=\"all\"))\n",
    "#ds_tr=ds_tr.T\n",
    "#ds_tr=ds_tr[[\"count\", \"mean\", \"std\", \"min\", \"50%\", \"max\"]]\n",
    "#ds_tr=ds_tr.round(2)\n",
    "\n",
    "#Test:\n",
    "#df_tt[\"bathrooms\"]=df_tt[\"bathrooms\"].astype(\"float\")\n",
    "#ds_tt=(df_tt[[\"tipo_Apartamento\", \"surface_total\", \"bedrooms\", \"bathrooms\"]].describe(include=\"all\"))\n",
    "#ds_tt=ds_tt.T\n",
    "#ds_tt=ds_tt[[\"count\", \"mean\", \"std\", \"min\", \"50%\", \"max\"]]\n",
    "#ds_tt=ds_tt.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2031,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Imputar metros cuadrados\n",
    "###Metros     [0-9]+\\,*\\.*\\s*[0-9]+\\s*m[0-9]*[a-z]*[0-9]*\n",
    "##Baños       [0-9]\\s*ba[a-z]*\n",
    "## admin      [0-9]*\\s*[a-z]*\\s*[a-z]*\\s*ad[a-z]*\\s*[0-9]*\n",
    "## arriendo   [0-9]*\\s*[a-z]*\\s*arr[a-z]*\\s*[0-9]*\\.*\\'*[0-9]*\\.*[0-9]*\n",
    "## Precio venta\n",
    "\n",
    "\n",
    "##Piscinas pi[a-z][a-z][a-z]+\n",
    "## Zona verde  zona[a-z]*\\s*verde[a-z]*\n",
    "## “sala chimenea”  sala\\s*[a-z]*\\s*[a-z]*\\s*chim[a-z]*\n",
    "## espectacular espe[a-z]*r\n",
    "## ascensor privado as*c*ensor\\s*priv*b*ado\n",
    "## pisos madera  pi*s*os*\\s*madera*\n",
    "## “comedor independiente” comedor*\\s*in*m*depen(diente)*\n",
    "### “pisos ceramica” pi*s*os*\\s*c*s*erami(ca)*\n",
    "## “salon social” salo*n*\\s*so*c*s*ial\n",
    "# vigilancia  vig*j*ilan(c*s*i)*  seguridad \n",
    "## “red gas” red\\s*gas*\n",
    "## “centro comercial”  centr*o*\\s*comerc*s*i*al*\n",
    "## “transporte publico”  \n",
    "## condominio  condo*mi*nio\n",
    "## campestre cam*n*pe*s*tr*e\n",
    "## penthouse pe*nt*\\s*hous*c*e\n",
    "## apartaestudio apa*r*ta*o*\\s*est*u*di*o\n",
    "## remodelado remo*delado* reformado reformado* estrenar es*tre*nar*\n",
    "## ascensor as*c*ens*z*or*\n",
    "## duplex dupl*ex*\n",
    "## jacuzzi jacuzz*i\n",
    "## gimnasio gi*y*mn*a*c*s*i*o*\n",
    "## esquinero esqu*inero*a*\n",
    "## aire acondicionado aire's*acondicionado\n",
    "## local lo*cal*\n",
    "## vista v*b*ista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2032,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3550362579466143"
      ]
     },
     "execution_count": 2032,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "destr=df_tr['description'].tolist()\n",
    "destt=df_tt['description'].tolist()\n",
    "\n",
    "desttr=df_tr['title'].tolist()\n",
    "desttt=df_tt['title'].tolist()\n",
    "##Extraer metros *********************************************************************************\n",
    "#****Train************************************\n",
    "listametrostr=([re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i).group() if bool(re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i))==True else '0'\n",
    "for i in destr ])\n",
    "metrostr=([re.search(r'[0-9]+',i).group() for i in listametrostr])\n",
    "df_tr[\"metros\"]=pd.DataFrame(metrostr)\n",
    "df_tr[\"metros\"]=df_tr[\"metros\"].astype(float)\n",
    "\n",
    "#del titulo\n",
    "listametrosttr=([re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i).group() \n",
    "if bool(re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i))==True else '0'\n",
    "for i in desttr ])\n",
    "metrosttr=([re.search(r'[0-9]+',i).group() for i in listametrosttr])\n",
    "df_tr[\"metrost\"]=pd.DataFrame(metrosttr)\n",
    "df_tr[\"metrost\"]=df_tr[\"metrost\"].astype(float)\n",
    "\n",
    "#imputar suface total\n",
    "df_tr[\"surface_total\"].fillna('', inplace=True)\n",
    "df_tr[\"surface_covered\"].fillna('', inplace=True)\n",
    "df_tr[\"surface_totalimp\"]=np.where(df_tr[\"surface_total\"]=='',df_tr[\"metros\"],df_tr[\"surface_total\"])\n",
    "df_tr[\"surface_totalimp\"]=np.where(df_tr[\"surface_total\"]==0,df_tr[\"metrost\"],df_tr[\"surface_totalimp\"])\n",
    "\n",
    "df_tr[\"surface_totalimp\"]=np.where(df_tr[\"surface_totalimp\"]==0, df_tr[\"surface_covered\"], df_tr[\"surface_totalimp\"])\n",
    "df_tr[\"surface_totalimp\"]=np.where(df_tr[\"surface_totalimp\"]=='', np.nan,df_tr[\"surface_totalimp\"])\n",
    "df_tr[\"surface_totalimp\"].isnull().sum()/len(df_tr) #35.50 % missings\n",
    "\n",
    "#****Test********************\n",
    "listametrostt=([re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i).group() \n",
    "if bool(re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i))==True else '0'\n",
    "for i in destt ])\n",
    "metrostt=([re.search(r'[0-9]+',i).group() for i in listametrostt])\n",
    "df_tt[\"metros\"]=pd.DataFrame(metrostt)\n",
    "df_tt[\"metros\"]=df_tt[\"metros\"].astype(float)\n",
    "\n",
    "#del titulo\n",
    "listametrosttt=([re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i).group() \n",
    "if bool(re.search(r'[0-9]+\\,*\\.*[0-9]+\\s*m[0-9]*e*t*r*o*s*[0-9]*', i))==True else '0'\n",
    "for i in desttt ])\n",
    "metrosttt=([re.search(r'[0-9]+',i).group() for i in listametrosttt])\n",
    "df_tt[\"metrost\"]=pd.DataFrame(metrosttt)\n",
    "df_tt[\"metrost\"]=df_tt[\"metrost\"].astype(float)\n",
    "\n",
    "#imputar suface total\n",
    "df_tt[\"surface_total\"].fillna('', inplace=True)\n",
    "df_tt[\"surface_covered\"].fillna('', inplace=True)\n",
    "df_tt[\"surface_totalimp\"]=np.where(df_tt[\"surface_total\"]=='',df_tt[\"metros\"],df_tt[\"surface_total\"])\n",
    "df_tt[\"surface_totalimp\"]=np.where(df_tt[\"surface_total\"]==0,df_tt[\"metrost\"],df_tt[\"surface_totalimp\"])\n",
    "\n",
    "df_tt[\"surface_totalimp\"]=np.where(df_tt[\"surface_totalimp\"]==0, df_tt[\"surface_covered\"], df_tt[\"surface_totalimp\"])\n",
    "df_tt[\"surface_totalimp\"]=np.where(df_tt[\"surface_totalimp\"]=='', np.nan,df_tt[\"surface_totalimp\"])\n",
    "df_tr[\"surface_totalimp\"].isnull().sum()/len(df_tr) #35.50 % missings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2033,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4734"
      ]
     },
     "execution_count": 2033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Baños****************************\n",
    "#imputar baños\n",
    "#Train****************************************************\n",
    "listabanostr=([re.search(r'[0-9]\\s*ba(?!l)[a-z]*', i).group() \n",
    "if bool(re.search(r'[0-9]\\s*ba(?!l)[a-z]*', i))==True else '0'\n",
    "for i in destr ])\n",
    "listabanostr\n",
    "banostr=([re.search(r'[0-9]+',i).group() if bool(re.search(r'[0-9]+',i))==True else 0 for i in listabanostr])\n",
    "banostr\n",
    "df_tr[\"banos\"]=pd.DataFrame(banostr)\n",
    "df_tr[\"banos\"]=df_tr[\"banos\"].astype(float)\n",
    "##Imputar baños\n",
    "df_tr[\"bathrooms\"].fillna(' ', inplace=True)\n",
    "df_tr[\"bathrooms\"]=np.where(df_tr[\"bathrooms\"]==' ', df_tr[\"banos\"], df_tr[\"bathrooms\"])\n",
    "df_tr[\"bathrooms\"]=np.where(df_tr[\"bathrooms\"]==0, df_tr[\"bedrooms\"]/1.5, df_tr[\"bathrooms\"])\n",
    "\n",
    "#Test************************************************\n",
    "listabanostt=([re.search(r'[0-9]\\s*ba(?!l)[a-z]*', i).group() \n",
    "if bool(re.search(r'[0-9]\\s*ba(?!l)[a-z]*', i))==True else '0'\n",
    "for i in destt])\n",
    "banostt=([re.search(r'[0-9]+',i).group() if bool(re.search(r'[0-9]+',i))==True else 0 for i in listabanostt])\n",
    "df_tt[\"banos\"]=pd.DataFrame(banostt)\n",
    "df_tt[\"banos\"]=df_tt[\"banos\"].astype(float)\n",
    "##Imputar baños\n",
    "df_tt[\"bathrooms\"].fillna(' ', inplace=True)\n",
    "df_tt[\"bathrooms\"]=np.where(df_tt[\"bathrooms\"]==' ', df_tt[\"banos\"], df_tt[\"bathrooms\"])\n",
    "df_tt[\"bathrooms\"]=np.where(df_tt[\"bathrooms\"]==0, df_tt[\"bedrooms\"]/1.5, df_tt[\"bathrooms\"])\n",
    "\n",
    "##Imputar precio cali****************************************************\n",
    "listapreciostt=([re.search(r'(valor|precio|venta)\\s*[0-9]*\\.*\\,*[0-9]*', i).group() \n",
    "if bool(re.search(r'(valor|precio|venta)\\s*[0-9]*\\.*\\,*[0-9]*', i))==True else 'nan'\n",
    "for i in destt ])\n",
    "\n",
    "preciostt=([re.search(r'[0-9]+',i).group() if bool(re.search(r'[0-9]+',i))==True else np.nan for i in listapreciostt])\n",
    "df_tt[\"precios\"]=pd.DataFrame(preciostt)\n",
    "df_tt[\"precios\"]=df_tt[\"precios\"].astype(float)\n",
    "df_tt[\"precios\"]=np.where(df_tt[\"precios\"]<40,np.nan,df_tt[\"precios\"])\n",
    "df_tt[\"precios\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creacion de dummies\n",
    "#piscina\n",
    "destr=df_tr['description'].tolist()\n",
    "list=[bool(re.search(r'pis*c*ina', i)) for i in destr]\n",
    "df_tr['piscina']=pd.DataFrame(list)\n",
    "destt=df_tt['description'].tolist()\n",
    "listtt=[bool(re.search(r'pis*c*ina', i)) for i in destt]\n",
    "df_tt['piscina']=pd.DataFrame(listtt)\n",
    "\n",
    "#zona verde \n",
    "list=[bool(re.search(r'zona[a-z]*\\s*verde[a-z]*', i)) for i in destr]\n",
    "df_tr['zonav']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'zona[a-z]*\\s*verde[a-z]*', i)) for i in destt]\n",
    "df_tt['zonav']=pd.DataFrame(listtt)\n",
    "\n",
    "#chimenea\n",
    "list=[bool(re.search(r'chime[a-z]*', i)) for i in destr]\n",
    "df_tr['chim']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'chime[a-z]*', i)) for i in destt]\n",
    "df_tt['chim']=pd.DataFrame(listtt)\n",
    "\n",
    "#espectacular\n",
    "list=[bool(re.search(r'espe[a-z]*r', i)) for i in destr]\n",
    "df_tr['espectacular']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'espe[a-z]*r', i)) for i in destt]\n",
    "df_tt['espectacular']=pd.DataFrame(listtt)\n",
    "\n",
    "#ascensor privado\n",
    "list=[bool(re.search(r'as*c*ensor\\s*priv*b*ado', i)) for i in destr]\n",
    "df_tr['ascensorpriv']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'as*c*ensor\\s*priv*b*ado', i)) for i in destt]\n",
    "df_tt['ascensorpriv']=pd.DataFrame(listtt)\n",
    "\n",
    "#piso madera\n",
    "list=[bool(re.search(r'pi*s*os*\\s*madera*', i)) for i in destr]\n",
    "df_tr['pisomadera']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'pi*s*os*\\s*madera*', i)) for i in destt]\n",
    "df_tt['pisomadera']=pd.DataFrame(listtt)\n",
    "\n",
    "#comedor independiente\n",
    "list=[bool(re.search(r'comedor*\\s*in*m*depen(diente)*', i)) for i in destr]\n",
    "df_tr['comedorind']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'comedor*\\s*in*m*depen(diente)*', i)) for i in destt]\n",
    "df_tt['comedorind']=pd.DataFrame(listtt)\n",
    "\n",
    "#piso ceramica\n",
    "list=[bool(re.search(r'pi*s*os*\\s*c*s*erami(ca)*', i)) for i in destr]\n",
    "df_tr['pisoceramica']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'pi*s*os*\\s*c*s*erami(ca)*', i)) for i in destt]\n",
    "df_tt['pisoceramica']=pd.DataFrame(listtt)\n",
    "\n",
    "#salon social\n",
    "list=[bool(re.search(r'salo*n*\\s*so*c*s*ial', i)) for i in destr]\n",
    "df_tr['salonsocial']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'salo*n*\\s*so*c*s*ial', i)) for i in destt]\n",
    "df_tt['salonsocial']=pd.DataFrame(listtt)\n",
    "\n",
    "#vigilancia\n",
    "list=[bool(re.search(r'vig*j*ilan(c*s*i)*', i)) for i in destr]\n",
    "df_tr['vigilancia']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'vig*j*ilan(c*s*i)*', i)) for i in destt]\n",
    "df_tt['vigilancia']=pd.DataFrame(listtt)\n",
    "\n",
    "#seguridad\n",
    "list=[bool(re.search(r'seguridad*', i)) for i in destr]\n",
    "df_tr['seguridad']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'seguridad*', i)) for i in destt]\n",
    "df_tt['seguridad']=pd.DataFrame(listtt)\n",
    "\n",
    "#red gas\n",
    "list=[bool(re.search(r'red\\s*gas*', i)) for i in destr]\n",
    "df_tr['redgas']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'red\\s*gas*', i)) for i in destt]\n",
    "df_tt['redgas']=pd.DataFrame(listtt)\n",
    "\n",
    "#centrocomercial\n",
    "list=[bool(re.search(r'centr*o*\\s*comerc*s*i*al*', i)) for i in destr]\n",
    "df_tr['centrocom']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'centr*o*\\s*comerc*s*i*al*', i)) for i in destt]\n",
    "df_tt['centrocom']=pd.DataFrame(listtt)\n",
    "\n",
    "#transporte publico\n",
    "list=[bool(re.search(r'transporte\\s*publico', i)) for i in destr]\n",
    "df_tr['transportep']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'transporte\\s*publico', i)) for i in destt]\n",
    "df_tt['transportep']=pd.DataFrame(listtt)\n",
    "\n",
    "#condominio\n",
    "list=[bool(re.search(r'condo*mi*nio', i)) for i in destr]\n",
    "df_tr['condominio']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'condo*mi*nio', i)) for i in destt]\n",
    "df_tt['condominio']=pd.DataFrame(listtt)\n",
    "\n",
    "#campestre\n",
    "list=[bool(re.search(r'cam*n*pe*s*tr*e', i)) for i in destr]\n",
    "df_tr['campestre']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'cam*n*pe*s*tr*e', i)) for i in destt]\n",
    "df_tt['campestre']=pd.DataFrame(listtt)\n",
    "\n",
    "#penthouse \n",
    "list=[bool(re.search(r'pe*nt*\\s*hous*c*e', i)) for i in destr]\n",
    "df_tr['penthouse']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'pe*nt*\\s*hous*c*e', i)) for i in destt]\n",
    "df_tt['penthouse']=pd.DataFrame(listtt)\n",
    "\n",
    "#apartaestudio\n",
    "list=[bool(re.search(r'apa*r*ta*o*\\s*est*u*di*o', i)) for i in destr]\n",
    "df_tr['apartaestudio']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'apa*r*ta*o*\\s*est*u*di*o', i)) for i in destt]\n",
    "df_tt['apartaestudio']=pd.DataFrame(listtt)\n",
    "\n",
    "#reformado \n",
    "list=[bool(re.search(r'remo*delado*', i)) for i in destr]\n",
    "df_tr['remodelado']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'remo*delado*', i)) for i in destt]\n",
    "df_tt['remodelado']=pd.DataFrame(listtt)\n",
    "\n",
    "#reformado\n",
    "list=[bool(re.search(r'reformado*', i)) for i in destr]\n",
    "df_tr['reformado']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'reformado*', i)) for i in destt]\n",
    "df_tt['reformado']=pd.DataFrame(listtt)\n",
    "\n",
    "#estrenar\n",
    "list=[bool(re.search(r'es*tre*nar*', i)) for i in destr]\n",
    "df_tr['estrenar']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'es*tre*nar*', i)) for i in destt]\n",
    "df_tt['estrenar']=pd.DataFrame(listtt)\n",
    "\n",
    "#ascensor\n",
    "list=[bool(re.search(r'as*c*ens*z*or*', i)) for i in destr]\n",
    "df_tr['ascensor']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'as*c*ens*z*or*', i)) for i in destt]\n",
    "df_tt['ascensor']=pd.DataFrame(listtt)\n",
    "\n",
    "#duplex\n",
    "list=[bool(re.search(r'dupl*ex*', i)) for i in destr]\n",
    "df_tr['duplex']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'dupl*ex*', i)) for i in destt]\n",
    "df_tt['duplex']=pd.DataFrame(listtt)\n",
    "\n",
    "#jacuzzi\n",
    "list=[bool(re.search(r'jacuzz*i', i)) for i in destr]\n",
    "df_tr['jacuzzi']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'jacuzz*i', i)) for i in destt]\n",
    "df_tt['jacuzzi']=pd.DataFrame(listtt)\n",
    "\n",
    "#gimnasio \n",
    "list=[bool(re.search(r'gi*y*mn*a*c*s*i*o*', i)) for i in destr]\n",
    "df_tr['gym']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'gi*y*mn*a*c*s*i*o*', i)) for i in destt]\n",
    "df_tt['gym']=pd.DataFrame(listtt)\n",
    "\n",
    "#esquinero  \n",
    "list=[bool(re.search(r'esqu*inero*a*', i)) for i in destr]\n",
    "df_tr['esquinero']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'esqu*inero*a*', i)) for i in destt]\n",
    "df_tt['esquinero']=pd.DataFrame(listtt)\n",
    "\n",
    "#aire acondicionado   aire's*acondicionado\n",
    "list=[bool(re.search(r'aire\\sacondicionado', i)) for i in destr]\n",
    "df_tr['ac']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'aire\\sacondicionado', i)) for i in destt]\n",
    "df_tt['ac']=pd.DataFrame(listtt)\n",
    "\n",
    "#local lo*cal*\n",
    "list=[bool(re.search(r'lo*cal*', i)) for i in destr]\n",
    "df_tr['local']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'lo*cal*', i)) for i in destt]\n",
    "df_tt['local']=pd.DataFrame(listtt)\n",
    "\n",
    "#vista v*b*ista\n",
    "list=[bool(re.search(r'v*b*ista', i)) for i in destr]\n",
    "df_tr['vista']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'v*b*ista', i)) for i in destt]\n",
    "df_tt['vista']=pd.DataFrame(listtt)\n",
    "\n",
    "#parqueadero\n",
    "list=[bool(re.search(r'parqu*eadero', i)) for i in destr]\n",
    "df_tr['parqueadero']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'parqu*eadero', i)) for i in destt]\n",
    "df_tt['parqueadero']=pd.DataFrame(listtt)\n",
    "\n",
    "#garage\n",
    "list=[bool(re.search(r'garage', i)) for i in destr]\n",
    "df_tr['garage']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'garage', i)) for i in destt]\n",
    "df_tt['garage']=pd.DataFrame(listtt)\n",
    "\n",
    "#Terraza\n",
    "list=[bool(re.search(r'terr*az*s*a', i)) for i in destr]\n",
    "df_tr['terraza']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'terr*az*s*a', i)) for i in destt]\n",
    "df_tt['terraza']=pd.DataFrame(listtt)\n",
    "\n",
    "#balcon\n",
    "list=[bool(re.search(r'balco*n', i)) for i in destr]\n",
    "df_tr['balcon']=pd.DataFrame(list)\n",
    "listtt=[bool(re.search(r'balco*n', i)) for i in destt]\n",
    "df_tt['balcon']=pd.DataFrame(listtt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=([\"piscina\", \"zonav\", \"chim\", \"espectacular\", \"ascensorpriv\", \"pisomadera\", \"comedorind\", \"pisoceramica\", \"salonsocial\", \n",
    "\"vigilancia\", \"seguridad\", \"redgas\", \"centrocom\", \"transportep\", \"condominio\", \"campestre\", \"penthouse\", \"apartaestudio\", \n",
    "\"remodelado\", \"reformado\", \"estrenar\", \"ascensor\", \"duplex\", \"jacuzzi\", \"gym\", \"esquinero\", \"ac\", \"local\", \"vista\", \n",
    "\"parqueadero\", \"garage\", \"terraza\", \"balcon\"]) #lista que contenga todas las variables creadas\n",
    "for i in dummies:\n",
    "    df_tr[i]=df_tr[i].astype(int)\n",
    "    df_tt[i]=df_tt[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juand\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "###Import da\n",
    "base=pd.read_csv(\"datosgeoesp2.csv\", index_col=False)\n",
    "base2=pd.read_csv(\"datosgeo.csv\", index_col=False)\n",
    "base2=base2[\"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=pd.merge(base,base2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=base.rename(columns={'city_y': 'city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Merge dato geografico\n",
    "basetest=base[base[\"city\"]==\"Cali\"]\n",
    "base22=base[base[\"city\"]==\"Bogotá D.C\"]\n",
    "base3=base[base[\"city\"]==\"Medellín\"]\n",
    "basetr=base22.append(base3)\n",
    "\n",
    "#df_tr3=pd.merge(df_tr,basetr, on=\"property_id\")\n",
    "#df_tt3=pd.merge(df_tt,basetest, on=\"property_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr3=pd.merge(basetr, df_tr ,on=\"property_id\")\n",
    "df_tt3=pd.merge(basetest, df_tt, on=\"property_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr2=df_tr3[['price', 'surface_totalimp' ,'bedrooms', 'bathrooms', 'tipo_Apartamento' ,'banos', 'piscina', 'zonav', \n",
    "'chim', 'espectacular', 'ascensorpriv', 'pisomadera', 'comedorind', 'pisoceramica', 'salonsocial', 'vigilancia', 'seguridad', 'redgas',\n",
    "'centrocom', 'transportep', 'condominio', 'campestre', 'penthouse',\n",
    "       'apartaestudio', 'remodelado', 'reformado', 'estrenar', 'ascensor',\n",
    "       'duplex', 'jacuzzi', 'gym', 'esquinero', 'ac', 'local', 'vista',\n",
    "       'parqueadero', 'garage', 'terraza', 'balcon' ,'med_H_NRO_CUARTOS',\n",
    "       'sum_HA_TOT_PER', 'med_V_TOT_HOG' ,'dist_cent',\n",
    "       'dist_air', 'dist_bus', 'dist_hosp', 'dist_pol', 'dist_shop',\n",
    "       'dist_bar', 'dist_univ', 'dist_rest', 'dist_scho', 'dist_park',\n",
    "       'dist_water', 'dist_road', 'dist_cent2', 'dist_air2', 'dist_bus2',\n",
    "       'dist_hosp2', 'dist_pol2', 'dist_shop2', 'dist_bar2', 'dist_univ2',\n",
    "       'dist_rest2', 'dist_scho2', 'dist_park2', 'dist_water2', 'dist_road2',\n",
    "       'med_H_Cuar_KNN', 'sum_TOT_Per_KNN', 'med_TOT_Hog_KNN', 'med_Estrato']]\n",
    "\n",
    "df_tt2=df_tt3[[ 'surface_totalimp' ,'bedrooms', 'bathrooms', 'tipo_Apartamento' ,'banos', 'piscina', 'zonav', \n",
    "'chim', 'espectacular', 'ascensorpriv', 'pisomadera', 'comedorind', 'pisoceramica', 'salonsocial', 'vigilancia', 'seguridad', 'redgas',\n",
    "'centrocom', 'transportep', 'condominio', 'campestre', 'penthouse',\n",
    "       'apartaestudio', 'remodelado', 'reformado', 'estrenar', 'ascensor',\n",
    "       'duplex', 'jacuzzi', 'gym', 'esquinero', 'ac', 'local', 'vista',\n",
    "       'parqueadero', 'garage', 'terraza', 'balcon' ,'med_H_NRO_CUARTOS',\n",
    "       'sum_HA_TOT_PER', 'med_V_TOT_HOG' ,'dist_cent',\n",
    "       'dist_air', 'dist_bus', 'dist_hosp', 'dist_pol', 'dist_shop',\n",
    "       'dist_bar', 'dist_univ', 'dist_rest', 'dist_scho', 'dist_park',\n",
    "       'dist_water', 'dist_road', 'dist_cent2', 'dist_air2', 'dist_bus2',\n",
    "       'dist_hosp2', 'dist_pol2', 'dist_shop2', 'dist_bar2', 'dist_univ2',\n",
    "       'dist_rest2', 'dist_scho2', 'dist_park2', 'dist_water2', 'dist_road2',\n",
    "       'med_H_Cuar_KNN', 'sum_TOT_Per_KNN', 'med_TOT_Hog_KNN', 'med_Estrato']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imputar missings de surface\n",
    "imputer=KNNImputer(n_neighbors=19)\n",
    "simputtr=imputer.fit_transform(np.array(df_tr2))\n",
    "simputte=imputer.fit_transform(np.array(df_tt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trfinal=pd.DataFrame(simputtr)\n",
    "df_testfinal=pd.DataFrame(simputte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trfinal.columns=df_tr2.columns\n",
    "df_testfinal.columns=df_tt2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Redondear variables\n",
    "df_trfinal[\"med_H_Cuar_KNN\"]=df_trfinal[\"med_H_Cuar_KNN\"].round(0)\n",
    "df_testfinal[\"med_H_Cuar_KNN\"]=df_testfinal[\"med_H_Cuar_KNN\"].round(0)\n",
    "\n",
    "df_trfinal[\"sum_TOT_Per_KNN\"]=df_trfinal[\"sum_TOT_Per_KNN\"].round(0)\n",
    "df_testfinal[\"sum_TOT_Per_KNN\"]=df_testfinal[\"sum_TOT_Per_KNN\"].round(0)\n",
    "\n",
    "df_trfinal[\"med_TOT_Hog_KNN\"]=df_trfinal[\"med_TOT_Hog_KNN\"].round(0)\n",
    "df_testfinal[\"med_TOT_Hog_KNN\"]=df_testfinal[\"med_TOT_Hog_KNN\"].round(0)\n",
    "\n",
    "df_trfinal[\"med_Estrato\"]=df_trfinal[\"med_Estrato\"].round(0)\n",
    "df_testfinal[\"med_Estrato\"]=df_testfinal[\"med_Estrato\"].round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Estandarizar \n",
    "\n",
    "cont=['price', 'surface_totalimp','med_H_NRO_CUARTOS', 'sum_HA_TOT_PER', 'med_V_TOT_HOG', 'dist_cent',\n",
    "       'dist_air', 'dist_bus', 'dist_hosp', 'dist_pol', 'dist_shop',\n",
    "       'dist_bar', 'dist_univ', 'dist_rest', 'dist_scho', 'dist_park',\n",
    "       'dist_water', 'dist_road', 'dist_cent2', 'dist_air2', 'dist_bus2',\n",
    "       'dist_hosp2', 'dist_pol2', 'dist_shop2', 'dist_bar2', 'dist_univ2',\n",
    "       'dist_rest2', 'dist_scho2', 'dist_park2', 'dist_water2', 'dist_road2',\n",
    "       'med_H_Cuar_KNN', 'sum_TOT_Per_KNN', 'med_TOT_Hog_KNN', 'bedrooms', 'bathrooms']\n",
    "\n",
    "cont2=['surface_totalimp','med_H_NRO_CUARTOS', 'sum_HA_TOT_PER', 'med_V_TOT_HOG', 'dist_cent',\n",
    "       'dist_air', 'dist_bus', 'dist_hosp', 'dist_pol', 'dist_shop',\n",
    "       'dist_bar', 'dist_univ', 'dist_rest', 'dist_scho', 'dist_park',\n",
    "       'dist_water', 'dist_road', 'dist_cent2', 'dist_air2', 'dist_bus2',\n",
    "       'dist_hosp2', 'dist_pol2', 'dist_shop2', 'dist_bar2', 'dist_univ2',\n",
    "       'dist_rest2', 'dist_scho2', 'dist_park2', 'dist_water2', 'dist_road2',\n",
    "       'med_H_Cuar_KNN', 'sum_TOT_Per_KNN', 'med_TOT_Hog_KNN', 'bedrooms', 'bathrooms']\n",
    "\n",
    "for x in df_trfinal:\n",
    "    if x in cont:\n",
    "        df_trfinal[x]=(df_trfinal[x] - df_trfinal[x].mean()) / df_trfinal[x].std()\n",
    "\n",
    "for x in df_testfinal:\n",
    "    if x in cont2:\n",
    "        df_testfinal[x]=( df_testfinal[x] - df_testfinal[x].mean() ) / df_testfinal[x].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get dummies restantes\n",
    "est_d=pd.get_dummies(df_trfinal[\"med_Estrato\"], prefix=\"est\")\n",
    "df_trfinal=pd.merge(df_trfinal, est_d, left_index=True, right_index=True)\n",
    "\n",
    "est_dt=pd.get_dummies(df_testfinal[\"med_Estrato\"], prefix=\"est\")\n",
    "df_testfinal=pd.merge(df_testfinal, est_dt, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df_trfinal[['surface_totalimp', 'bedrooms', 'bathrooms',\n",
    "       'tipo_Apartamento', 'banos', 'piscina', 'zonav', 'chim', 'espectacular',\n",
    "       'ascensorpriv', 'pisomadera', 'comedorind', 'pisoceramica',\n",
    "       'salonsocial', 'vigilancia', 'seguridad', 'redgas', 'centrocom',\n",
    "       'transportep', 'condominio', 'campestre', 'penthouse', 'apartaestudio',\n",
    "       'remodelado', 'reformado', 'estrenar', 'ascensor', 'duplex', 'jacuzzi',\n",
    "       'gym', 'esquinero', 'ac', 'local', 'vista', 'parqueadero', 'garage',\n",
    "       'terraza', 'balcon', 'med_H_NRO_CUARTOS', 'sum_HA_TOT_PER',\n",
    "       'med_V_TOT_HOG', 'dist_cent', 'dist_air', 'dist_bus', 'dist_hosp',\n",
    "       'dist_pol', 'dist_shop', 'dist_bar', 'dist_univ', 'dist_rest',\n",
    "       'dist_scho', 'dist_park', 'dist_water', 'dist_road', 'dist_cent2',\n",
    "       'dist_air2', 'dist_bus2', 'dist_hosp2', 'dist_pol2', 'dist_shop2',\n",
    "       'dist_bar2', 'dist_univ2', 'dist_rest2', 'dist_scho2', 'dist_park2',\n",
    "       'dist_water2', 'dist_road2', 'med_H_Cuar_KNN', 'sum_TOT_Per_KNN',\n",
    "       'med_TOT_Hog_KNN', 'est_1.0', 'est_2.0',\n",
    "       'est_4.0', 'est_5.0', 'est_6.0']]\n",
    "\n",
    "x_test=df_testfinal[['surface_totalimp', 'bedrooms', 'bathrooms',\n",
    "       'tipo_Apartamento', 'banos', 'piscina', 'zonav', 'chim', 'espectacular',\n",
    "       'ascensorpriv', 'pisomadera', 'comedorind', 'pisoceramica',\n",
    "       'salonsocial', 'vigilancia', 'seguridad', 'redgas', 'centrocom',\n",
    "       'transportep', 'condominio', 'campestre', 'penthouse', 'apartaestudio',\n",
    "       'remodelado', 'reformado', 'estrenar', 'ascensor', 'duplex', 'jacuzzi',\n",
    "       'gym', 'esquinero', 'ac', 'local', 'vista', 'parqueadero', 'garage',\n",
    "       'terraza', 'balcon', 'med_H_NRO_CUARTOS', 'sum_HA_TOT_PER',\n",
    "       'med_V_TOT_HOG', 'dist_cent', 'dist_air', 'dist_bus', 'dist_hosp',\n",
    "       'dist_pol', 'dist_shop', 'dist_bar', 'dist_univ', 'dist_rest',\n",
    "       'dist_scho', 'dist_park', 'dist_water', 'dist_road', 'dist_cent2',\n",
    "       'dist_air2', 'dist_bus2', 'dist_hosp2', 'dist_pol2', 'dist_shop2',\n",
    "       'dist_bar2', 'dist_univ2', 'dist_rest2', 'dist_scho2', 'dist_park2',\n",
    "       'dist_water2', 'dist_road2', 'med_H_Cuar_KNN', 'sum_TOT_Per_KNN',\n",
    "       'med_TOT_Hog_KNN', 'est_1.0', 'est_2.0',\n",
    "       'est_4.0', 'est_5.0', 'est_6.0']]\n",
    "y_train=df_trfinal[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losscore(y,ypred):\n",
    "    penalty=np.abs(y-ypred)\n",
    "    penalty=np.where(penalty<0.066, np.exp(penalty),penalty)\n",
    "    penalty=np.where(penalty>0,np.exp(penalty),penalty)\n",
    "    abs_exp=np.mean(penalty)\n",
    "    return abs_exp\n",
    "\n",
    "losscore2=make_scorer(losscore, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\t\n",
    "models.append(xgb.XGBRegressor(n_estimators=10,eta=0.1, max_depth=1))\n",
    "models.append(xgb.XGBRegressor(n_estimators=100,eta=0.1, max_depth=1))\n",
    "models.append(xgb.XGBRegressor(n_estimators=500,eta=0.1, max_depth=1))\n",
    "models.append(xgb.XGBRegressor(n_estimators=10,eta=0.1, max_depth=5))\n",
    "models.append(xgb.XGBRegressor(n_estimators=100,eta=0.1, max_depth=5))\n",
    "models.append(xgb.XGBRegressor(n_estimators=500,eta=0.1, max_depth=5))\n",
    "models.append(xgb.XGBRegressor(n_estimators=10,eta=0.1, max_depth=10))\n",
    "models.append(xgb.XGBRegressor(n_estimators=100,eta=0.1, max_depth=10))\n",
    "models.append(xgb.XGBRegressor(n_estimators=500,eta=0.1, max_depth=10))\n",
    "\n",
    "models.append(MLPRegressor(hidden_layer_sizes=(100,1), alpha=0.001, random_state=911))\n",
    "models.append(MLPRegressor(hidden_layer_sizes=(250,5), alpha=0.001, random_state=911))\n",
    "models.append(MLPRegressor(hidden_layer_sizes=(100,1), alpha=0.1, random_state=911))\n",
    "models.append(MLPRegressor(hidden_layer_sizes=(250,5), alpha=0.1, random_state=911))\n",
    "models.append(MLPRegressor(hidden_layer_sizes=(100,1), alpha=1.5, random_state=911))\n",
    "models.append(MLPRegressor(hidden_layer_sizes=(250,5), alpha=1.5, random_state=911))\n",
    "\n",
    "models.append(Lasso(alpha=0))\n",
    "models.append(Lasso(alpha=0.05))\n",
    "models.append(Lasso(alpha=0.1))\n",
    "models.append(Lasso(alpha=0.2))\n",
    "models.append(Lasso(alpha=0.5))\n",
    "models.append(Lasso(alpha=1))\n",
    "models.append(Lasso(alpha=2))\n",
    "models.append(Lasso(alpha=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Super learner\n",
    "ensemble = SuperLearner(scorer=losscore2, random_state=911, verbose=2, folds=10)\n",
    "# Build the first layer XGBoost\n",
    "ensemble.add(models)\n",
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(LinearRegression())\n",
    "ensemble.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:11\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:01\n"
     ]
    }
   ],
   "source": [
    "xtr=np.array(x_train.head(30))\n",
    "xtest=np.array(x_test.head(30))\n",
    "\n",
    "ytrainpred=ensemble.predict(xtr)\n",
    "ytestpred=ensemble.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losscorep(y,ypred):\n",
    "    penalty=np.abs(y-ypred)\n",
    "    penalty=np.where(penalty<40000000, np.exp(penalty),penalty)\n",
    "    penalty=np.where(penalty>0,np.exp(penalty),penalty)\n",
    "    abs_exp=np.mean(penalty)\n",
    "    return abs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price    8.094723e+08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bog=df_tr[df_tr[\"city\"]==\"Bogotá D.C\"]\n",
    "med=df_tr[df_tr[\"city\"]==\"Medellín\"]\n",
    "bogprice=bog[\"price\"]\n",
    "bogprice=pd.DataFrame(bogprice)\n",
    "medprice=med[\"price\"]\n",
    "medprice=pd.DataFrame(medprice)\n",
    "pricesbogmed=bogprice.append(medprice)\n",
    "pricesbogmed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losscorep(y,ypred):\n",
    "    penalty=np.abs(y-ypred)\n",
    "    penalty=np.where(penalty>40000000, np.exp(penalty),penalty)\n",
    "    penalty=np.where(penalty>0,np.exp(penalty),penalty)\n",
    "    abs_exp=np.mean(penalty)\n",
    "    return abs_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475131167.7772107"
      ]
     },
     "execution_count": 1949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ytrainpred=pd.read_csv(\"y_preds_train.csv\")\n",
    "y_trainreal=np.array(df_tr[\"price\"])\n",
    "ytrainpredd=ytrainpred['0']*541552700.6981763+744197549.3413885\n",
    "ytrainpredd2=np.array(ytrainpredd)\n",
    "np.sqrt(mean_squared_error(y_trainreal,ytrainpredd2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98048843.30229585"
      ]
     },
     "execution_count": 1977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "error = mae(y_trainreal,ytrainpredd2)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1986,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.903177210742694e+17"
      ]
     },
     "execution_count": 1986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrainpred2=pd.read_csv(\"y_predsprior_train.csv\")\n",
    "y_trainreal=np.array(df_tr[\"price\"])\n",
    "ytrainpredd=ytrainpred2['0']*541552700.6981763+744197549.3413885\n",
    "ytrainpredd2=np.array(ytrainpredd)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_trainreal,ytrainpredd2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1988,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3838772772984986e+17"
      ]
     },
     "execution_count": 1988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = mae(y_trainreal,ytrainpredd2)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7818bfdb2515268f36f561cf\n",
       "1       b431f95918341a3680fd120c\n",
       "2       528d66663acd45b08c6d7931\n",
       "3       af7aede36ea1df2529081419\n",
       "4       ba8e68faaf298e1ede1e442d\n",
       "                  ...           \n",
       "4995    556fb5fa7897fb663ef41eb8\n",
       "4996    1f9782204f2e354bbb58268a\n",
       "4997    1c9a84f5a6f3ca8525e265ee\n",
       "4998    6b297b5f8b0cbc514d53abe6\n",
       "4999    083c76dbd9d170bed27c752b\n",
       "Name: property_id, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 2002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertyid=df_tt[\"property_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=pd.read_csv(\"y_predsprior_test.csv\")\n",
    "ypredtest=pd.merge(propertyid,ytest, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2107,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciosimp=df_tt[\"precios\"]\n",
    "ypredtest=pd.merge(ypredtest,preciosimp, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredtest[\"precios\"]=ypredtest[\"precios\"]*1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredtest[\"precios\"].fillna('', inplace=True)\n",
    "ypredtest['0']=np.where(ypredtest[\"precios\"]!='',ypredtest[\"precios\"],ypredtest['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2098,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_id', 'price', 'precios'], dtype='object')"
      ]
     },
     "execution_count": 2098,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypredtest=ypredtest.rename(columns={'0':\"price\"})\n",
    "ypredtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredtest=ypredtest[['property_id',\"price\"]]\n",
    "ypredtest.to_csv('predictions_Caraballo_Pinilla_Valencia.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1975,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1975-b120175aeddf>:2: RuntimeWarning: overflow encountered in exp\n",
      "  penalty=np.where(penalty>40000000, np.exp(penalty),penalty)\n",
      "<ipython-input-1975-b120175aeddf>:3: RuntimeWarning: overflow encountered in exp\n",
      "  penalty=np.where(penalty>0,np.exp(penalty),penalty)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 1975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty=np.abs(y_trainreal-ytrainpredd2)\n",
    "penalty=np.where(penalty>40000000, np.exp(penalty),penalty)\n",
    "penalty=np.where(penalty>0,np.exp(penalty),penalty)\n",
    "abs_exp=np.mean(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrainpred=pd.read_csv(\"y_preds_train.csv\")\n",
    "ytestpred=pd.read_csv(\"y_preds_test.csv\")\n",
    "\n",
    "#Desestandarizar\n",
    "ytrainpredd=ytrainpred*541552700.6981763+744197549.3413885\n",
    "ytestpredd=ytestpred*601842533+555314430\n",
    "priortr=df_tr[\"cdecil\"]\n",
    "\n",
    "ytrainpred2=pd.DataFrame(ytrainpredd)\n",
    "priortr2=pd.DataFrame(priortr)\n",
    "\n",
    "##Prior train\n",
    "y_prior=pd.merge(ytrainpred2,priortr2,left_index=True,right_index=True)\n",
    "y_prior2=np.array(y_prior)\n",
    "y_trainprior=np.array(df_tr[\"price\"])\n",
    "\n",
    "price=ytestpredd['0'].tolist()\n",
    "percentil=[stats.percentileofscore(price,i,kind='weak') for i in price]\n",
    "decil=pd.cut(percentil, bins=[0,10,20,30,40,50,60,70,80,90,100],labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "bog=df_tr[df_tr[\"city\"]==\"Bogotá D.C\"]\n",
    "med=df_tr[df_tr[\"city\"]==\"Medellín\"]\n",
    "bogprice=(bog[\"price\"]-236337171)*1.07\n",
    "bogprice=pd.DataFrame(bogprice)\n",
    "medprice=(med[\"price\"]-202000000)*1.36\n",
    "medprice=pd.DataFrame(medprice)\n",
    "pricesbogmed=bogprice.append(medprice)\n",
    "\n",
    "distrcali=choices(pricesbogmed, k=10000)\n",
    "distrcali=pd.DataFrame(distrcali)\n",
    "qtt=distrcali.quantile([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]).reset_index()\n",
    "\n",
    "diccortes=dict(zip(qtt.index, qtt[0]))\n",
    "decil=pd.DataFrame(decil).replace({'0':diccortes})\n",
    "\n",
    "##Prior test\n",
    "y_priortest=pd.merge(ytestpred2,decil,left_index=True,right_index=True)\n",
    "y_priortest2=np.array(y_priortest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr[\"price\"]=df_tr[\"price\"].astype(float)\n",
    "price=df_tr[\"price\"].tolist()\n",
    "\n",
    "###Priors\n",
    "percentile=[stats.percentileofscore(price,i,kind='weak') for i in price]\n",
    "df_tr[\"percentil\"]=pd.DataFrame(percentile)\n",
    "df_tr[\"decil\"]=pd.cut(df_tr[\"percentil\"], bins=[0,10,20,30,40,50,60,70,80,90,100],labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "df_tr[\"percentil\"]=pd.DataFrame(percentile)\n",
    "df_tr[\"decil\"]=pd.cut(df_tr[\"percentil\"], bins=[0,10,20,30,40,50,60,70,80,90,100],labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "##cortes deciles\n",
    "qtr=df_tr[\"price\"].quantile([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]).reset_index()\n",
    "qtr[\"index\"]=qtr[\"index\"]*10\n",
    "diccortes=dict(zip(qtr.index, qtr.price))\n",
    "df_tr[\"decil2\"]=df_tr[\"decil\"]\n",
    "df_tr[\"cdecil\"]=pd.DataFrame(df_tr[\"decil2\"]).replace({'decil2':diccortes})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Corte tercil test\n",
    "#simulacion montecarlo cortes\n",
    "diccortest=dict(zip(qtr.index, qtr.price))\n",
    "df_tt[\"decilp2\"]=df_tt[\"decilp\"]\n",
    "df_tt[\"cdecilp\"]=pd.DataFrame(df_tt[\"decilp2\"]).replace({'decilp2':diccortes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losscorep(y,ypred):\n",
    "    penalty=np.abs(y-ypred)\n",
    "    penalty=np.where(penalty<40000000, np.exp(penalty),penalty)\n",
    "    penalty=np.where(penalty>0,np.exp(penalty),penalty)\n",
    "    abs_exp=np.mean(penalty)\n",
    "    return abs_exp\n",
    "    \n",
    "losscore2p=make_scorer(losscorep, greater_is_better=False)\n",
    "\n",
    "####Super learner\n",
    "ensemble = SuperLearner(scorer=losscore2p, random_state=911, verbose=2, folds=10,n_jobs=-1)\n",
    "# Build the first layer XGBoost\n",
    "ensemble.add(models)\n",
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(xt,yt)\n",
    "preds = ensemble.predict(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsdf=pd.DataFrame(preds)\n",
    "predsdf.to_csv(\"y_preds_train.csv\",index=False)\n",
    "\n",
    "xtt=np.array(x_test)\n",
    "preds_cali = ensemble.predict(xtt)\n",
    "\n",
    "preds_calidf=pd.DataFrame(preds_cali)\n",
    "preds_calidf.to_csv(\"y_preds_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(y_trainprior-predicttrainprior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((y_trainprior-predicttrainprior)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.mean((np.abs(y_trainprior-predicttrainprior)**2.718)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.mean((np.abs(y_trainprior-ytrainpred)**2.718)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losscorep(y_trainprior,predicttrainprior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predpriordf=pd.DataFrame(predicttrainprior)\n",
    "predpriordf.to_csv(\"y_predsprior_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicttestprior = ensembleprior.predict(y_priortest2)\n",
    "predpriordf_cali=pd.DataFrame(predicttestprior)\n",
    "predpriordf_cali.to_csv(\"y_predsprior_test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "efb17e5bfbf4581ee388028022334b1903202e979e18a00399327c90fdf4addf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
